{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ahsan-fayyaz/Artificial-Intelligence/blob/main/Assignment_4/Assignment_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and pip installations (if needed)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "iris_data = load_iris()\n",
    "\n",
    "features = iris_data.data\n",
    "target =  iris_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                 5.1               3.5                1.4               0.2   \n",
       "1                 4.9               3.0                1.4               0.2   \n",
       "2                 4.7               3.2                1.3               0.2   \n",
       "3                 4.6               3.1                1.5               0.2   \n",
       "4                 5.0               3.6                1.4               0.2   \n",
       "5                 5.4               3.9                1.7               0.4   \n",
       "6                 4.6               3.4                1.4               0.3   \n",
       "7                 5.0               3.4                1.5               0.2   \n",
       "8                 4.4               2.9                1.4               0.2   \n",
       "9                 4.9               3.1                1.5               0.1   \n",
       "10                5.4               3.7                1.5               0.2   \n",
       "11                4.8               3.4                1.6               0.2   \n",
       "12                4.8               3.0                1.4               0.1   \n",
       "13                4.3               3.0                1.1               0.1   \n",
       "14                5.8               4.0                1.2               0.2   \n",
       "\n",
       "    target  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "5        0  \n",
       "6        0  \n",
       "7        0  \n",
       "8        0  \n",
       "9        0  \n",
       "10       0  \n",
       "11       0  \n",
       "12       0  \n",
       "13       0  \n",
       "14       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the first 15 rows of the data\n",
    "df_features = pd.DataFrame(features, columns=iris_data.feature_names)\n",
    "df_target = pd.DataFrame(target, columns=['target'])\n",
    "\n",
    "df = pd.concat([df_features, df_target], axis=1)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal length (cm)    150 non-null float64\n",
      "sepal width (cm)     150 non-null float64\n",
      "petal length (cm)    150 non-null float64\n",
      "petal width (cm)     150 non-null float64\n",
      "target               150 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 5.9 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "display(df.describe())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "\n",
    "Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names :  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target Names  :  ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Names : \",iris_data.feature_names)\n",
    "print(\"Target Names  : \",iris_data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After exploring the iris dataset, it can be observed that there are 4 features (4 columns)\n",
    "> 1. Septal Length (cm)\n",
    "> 2. Septal Width  (cm)\n",
    "> 3. Petal Length  (cm)\n",
    "> 4. Petal Width   (cm)\n",
    "\n",
    "> The label in the dataset divides into species classes (3 categories) -\n",
    "> where the values 0,1,2 correspond to the following different species\n",
    "> 1. Iris setosa (value = 0)\n",
    "> 2. Iris versicolor (value = 1)\n",
    "> 3. Iris virginica (value = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part 2: Split the dataset into train and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "X = features\n",
    "y = target\n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part 3: Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "LR_model = LogisticRegression()\n",
    "LR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions Probability:  [[0.05591523 0.65913963 0.28494514]]\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "LR_sample_dataset = X_test[:1]\n",
    "LR_pred = LR_model.predict_proba(LR_sample_dataset)\n",
    "print(\"Predictions Probability: \", LR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         5\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "# Here is the classification report for the model\n",
    "LR_y_pred = LR_model.predict(X_test)\n",
    "print(classification_report(y_test, LR_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[6 0 0]\n",
      " [0 4 0]\n",
      " [0 0 5]]\n",
      "\n",
      "\n",
      "Score :  1.0\n"
     ]
    }
   ],
   "source": [
    "#Here is the confusion matrix\n",
    "print(\"Confusion Matrix :\\n\",confusion_matrix(y_test, LR_y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Score : \", LR_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report on the score:\n",
    "> I ran a classification report on the model which determined precision of the model. The precision is 1.0\n",
    "\n",
    "> Precision measures how good our model is when the prediction is positive. The score is the coefficient of prediction, representing the model's capability to predict the correct classes. Here, we have a perfect score of 1.0\n",
    "\n",
    "> I also printed confusion matrix for this model and here are the results:\n",
    "> * 6 out of 6 True positives for setosa\n",
    "> * 6 out of 6 True positives for versicolor\n",
    "> * 3 out of 3 True positives for virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients :  [[ 0.37913418  1.44405025 -2.20416393 -0.99641481]\n",
      " [ 0.51982378 -1.63674234  0.44256066 -1.22218456]\n",
      " [-1.59429958 -1.63794573  2.43430576  2.38856193]]\n",
      "\n",
      "\n",
      "Intercepts:  [ 0.26022165  0.96602741 -1.1157134 ]\n"
     ]
    }
   ],
   "source": [
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "print(\"Coefficients : \", LR_model.coef_)\n",
    "print(\"\\n\")\n",
    "print(\"Intercepts: \", LR_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part 4: Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "SVM_model = svm.SVC(kernel=\"linear\", probability=True)\n",
    "SVM_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions Probability:  [[0.01319876 0.97526335 0.01153789]]\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "SVM_sample_dataset = X_test[:1]\n",
    "SVM_pred = SVM_model.predict_proba(SVM_sample_dataset)\n",
    "print(\"Predictions Probability: \", SVM_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      0.75      0.86         4\n",
      "           2       0.83      1.00      0.91         5\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        15\n",
      "   macro avg       0.94      0.92      0.92        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "\n",
    "SVM_y_pred = SVM_model.predict(X_test)\n",
    "print(\"\\nClassification Report : \",classification_report(y_test, SVM_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix :  [[6 0 0]\n",
      " [0 3 1]\n",
      " [0 0 5]]\n",
      "\n",
      "\n",
      "Score :  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Here is the confusion matrix\n",
    "print(\"\\nConfusion Matrix : \",confusion_matrix(y_test, SVM_y_pred))\n",
    "print(\"\\n\")\n",
    "SVM_score = SVM_model.score(X_test, y_test)\n",
    "print(\"Score : \", SVM_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report on the score:\n",
    "> For SVM, We have a score of 0.933. This depicts that the model fits pretty well although it doesn't have a perfect score like our Logistic Regression. Overall, the model fits pretty well giving us a score of 0.93 in SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part 5: Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(12, 6), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "NN_model = MLPClassifier(\n",
    "            solver='lbfgs', \n",
    "            alpha=1e-5, \n",
    "            hidden_layer_sizes=(12, 6), \n",
    "            random_state=1)\n",
    "NN_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [[4.33214753e-09 9.99994040e-01 5.95559621e-06]]\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "NN_sample_dataset = X_test[:1]\n",
    "NN_pred = NN_model.predict_proba(NN_sample_dataset)\n",
    "print(\"Predictions: \", NN_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      0.50      0.67         4\n",
      "           2       0.71      1.00      0.83         5\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        15\n",
      "   macro avg       0.90      0.83      0.83        15\n",
      "weighted avg       0.90      0.87      0.86        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "NN_y_pred = NN_model.predict(X_test)\n",
    "print(\"\\nClassification Report : \",classification_report(y_test, NN_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix :  [[6 0 0]\n",
      " [0 2 2]\n",
      " [0 0 5]]\n",
      "\n",
      "\n",
      "Score :  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "#Here is the confusion matrix\n",
    "print(\"\\nConfusion Matrix : \",confusion_matrix(y_test, NN_y_pred))\n",
    "print(\"\\n\")\n",
    "NN_score = NN_model.score(X_test, y_test)\n",
    "print(\"Score : \", NN_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report on the score:\n",
    "> I used the following parameters here:  \n",
    "> * solver='lbfgs', \n",
    "> * alpha=1e-5, \n",
    "> * hidden_layer_sizes=(12, 6), \n",
    "> * random_state=1\n",
    "\n",
    "> The model gave a score of 0.87 here. Our model predicts correct 86% of the times. We see that there were some true negatives in our result as shown in the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [[0.22360226 0.42756553 0.3488322 ]]\n",
      "\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      0.25      0.40         4\n",
      "           2       0.62      1.00      0.77         5\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        15\n",
      "   macro avg       0.88      0.75      0.72        15\n",
      "weighted avg       0.88      0.80      0.76        15\n",
      "\n",
      "\n",
      "Confusion Matrix :  [[6 0 0]\n",
      " [0 1 3]\n",
      " [0 0 5]]\n",
      "\n",
      "\n",
      "Score :  0.8\n"
     ]
    }
   ],
   "source": [
    "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
    "\n",
    "###Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "NN_model_2 = MLPClassifier(\n",
    "            learning_rate = \"adaptive\",\n",
    "            max_iter = 100,\n",
    "            activation = \"identity\",\n",
    "            alpha=1e-5, \n",
    "            hidden_layer_sizes=(12, 6), \n",
    "            random_state=0)\n",
    "NN_model_2.fit(X_train, y_train)\n",
    "\n",
    "###For a sample datapoint, predict the probabilities for each possible class\n",
    "NN_sample_dataset_2 = X_test[:1]\n",
    "NN_pred_2 = NN_model_2.predict_proba(NN_sample_dataset_2)\n",
    "print(\"Predictions: \", NN_pred_2)\n",
    "\n",
    "###Report on the score for the Neural Network, what does the score measure?\n",
    "NN_y_pred_2 = NN_model_2.predict(X_test)\n",
    "print(\"\\nClassification Report : \",classification_report(y_test, NN_y_pred_2))\n",
    "\n",
    "###Here is the confusion matrix\n",
    "print(\"\\nConfusion Matrix : \",confusion_matrix(y_test, NN_y_pred_2))\n",
    "print(\"\\n\")\n",
    "NN_score_2 = NN_model_2.score(X_test, y_test)\n",
    "print(\"Score : \", NN_score_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report on the score:\n",
    "> I used the following parameters here on the second version of MLP:\n",
    "> * learning_rate = \"adaptive\",\n",
    "> * max_iter = 100,\n",
    "> * activation = \"identity\",\n",
    "> * alpha=1e-5, \n",
    "> * hidden_layer_sizes=(12, 6), \n",
    "> * random_state=0\n",
    "\n",
    "> The model gave a score of 0.80\n",
    "> It seems as if the model became less accurate when I switched max_iter = \"100\" and random_state=0. Also, I changed activation parameter = \"identity\" which might also be the reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: K-Nearest Neighbors\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [[4.33214753e-09 9.99994040e-01 5.95559621e-06]]\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "KNN_sample_dataset = X_test[:1]\n",
    "KNN_pred = KNN_model.predict_proba(KNN_sample_dataset)\n",
    "print(\"Predictions: \", NN_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      0.75      0.86         4\n",
      "           2       0.83      1.00      0.91         5\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        15\n",
      "   macro avg       0.94      0.92      0.92        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "KNN_y_pred = KNN_model.predict(X_test)\n",
    "print(\"\\nClassification Report : \",classification_report(y_test, KNN_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix :  [[6 0 0]\n",
      " [0 3 1]\n",
      " [0 0 5]]\n",
      "\n",
      "\n",
      "Score :  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Here is the confusion matrix\n",
    "print(\"\\nConfusion Matrix : \",confusion_matrix(y_test, KNN_y_pred))\n",
    "print(\"\\n\")\n",
    "KNN_score = KNN_model.score(X_test, y_test)\n",
    "print(\"Score : \", KNN_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report on the score:\n",
    "> We have a score of 0.933 again. This depicts that the model fits pretty well to the data and gives us a fairly accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Conclusions and takeaways\n",
    "\n",
    "In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I ran 4 different algorithms in this notebook:\n",
    "> * Logistic Regression\n",
    "> * Support Vector Machine\n",
    "> * MLP Classifier (Neural Network)\n",
    "> * K-Nearest Neighbors\n",
    "\n",
    "> The models scored an accuracy between 80% and 100%. It is safe to say that the models did fairly well and the outputs did change upon changing the parameters. Logistic Regression was able to give us a 100% accuracy. However, it may also be the reason that we have a pretty small dataset (150 rows) and it may be due to overfitting.\n",
    "\n",
    "> The observation that surprised me was that max_iter parameter in Neural Network (MLP Classifier) had a huge impact on the score value. The score went really down when I put max_iter=10, however, I changed it to 100 for the second variation of the algorithm and it gave me a score of 80%. Overall, it is safe to say that Logistic regression made most sense due to the fact that it constructs linear boundaries to classify objects. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
